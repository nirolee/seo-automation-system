# -*- coding: utf-8 -*-
"""å¿«é€Ÿæµ‹è¯• - Googleçƒ­æœè·å–"""
import sys
import io

if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

import requests
from bs4 import BeautifulSoup

print("=" * 60)
print("ğŸ”¥ å¿«é€Ÿæ¼”ç¤º - Googleçƒ­æœè·å–")
print("=" * 60)
print("\nğŸ“¡ æ­£åœ¨è¿æ¥Google Trendsï¼ˆé€šè¿‡7890ä»£ç†ï¼‰...\n")

proxies = {
    'http': 'http://127.0.0.1:7890',
    'https': 'http://127.0.0.1:7890'
}

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
}

try:
    url = "https://trends.google.com/trends/trendingsearches/daily/rss?geo=US"
    response = requests.get(url, headers=headers, proxies=proxies, timeout=15)

    soup = BeautifulSoup(response.content, 'xml')
    items = soup.find_all('item')

    print(f"âœ… æˆåŠŸè·å– {len(items)} ä¸ªGoogleçƒ­æœè¯\n")
    print("ğŸ† Top 10 ç¾å›½çƒ­æœ:\n")

    for i, item in enumerate(items[:10], 1):
        title = item.find('title')
        traffic = item.find('ht:approx_traffic')
        if title:
            traffic_text = traffic.text if traffic else 'N/A'
            print(f"   {i:2d}. {title.text.strip()} ({traffic_text} searches)")

    print("\n" + "=" * 60)
    print("âœ… æµ‹è¯•æˆåŠŸï¼ä»£ç†å·¥ä½œæ­£å¸¸")
    print("=" * 60)
    print("\nğŸ’¡ æç¤ºï¼šè¿è¡Œå®Œæ•´å·¥å…·è·å–æ›´å¤šæ•°æ®ï¼š")
    print("   python trending-finder.py")

except requests.exceptions.ProxyError:
    print("âŒ ä»£ç†è¿æ¥å¤±è´¥\n")
    print("è¯·æ£€æŸ¥ï¼š")
    print("   1. ä»£ç†è½¯ä»¶æ˜¯å¦åœ¨è¿è¡Œï¼Ÿ")
    print("   2. ç«¯å£æ˜¯å¦ç¡®å®æ˜¯7890ï¼Ÿ")
    print("   3. æµè§ˆå™¨èƒ½å¦æ‰“å¼€ google.comï¼Ÿ")

except Exception as e:
    print(f"âŒ è·å–å¤±è´¥: {e}\n")
    print("å¯èƒ½çš„åŸå› ï¼š")
    print("   - ç½‘ç»œè¿æ¥é—®é¢˜")
    print("   - ä»£ç†è®¾ç½®ä¸æ­£ç¡®")
    print("   - Google TrendsæœåŠ¡æš‚æ—¶ä¸å¯ç”¨")
